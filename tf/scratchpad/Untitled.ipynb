{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'dbm': True,\n",
    "        'batch_size': 128,\n",
    "        'features': ['heading', 'lat', 'lon']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_dir(train_data_dir):\n",
    "    \"\"\"\n",
    "    Crawls directory specified in @train_data_dir\n",
    "    Assumes the master train folder is located at `cwd`../train\n",
    "    \"\"\"\n",
    "    clean_train_files = []\n",
    "    main_train_dir_path = pathlib.Path(\n",
    "        pathlib.PurePath(pathlib.Path.cwd()).parent, pathlib.Path('train'))\n",
    "    \n",
    "    for train_dir in [x for x in main_train_dir_path.iterdir()\n",
    "                      if x.is_dir() and '.' not in x.name]:\n",
    "        clean_dir = train_dir / str(train_data_dir)\n",
    "        for clean_train_file in [x for x in clean_dir.iterdir() if not x.is_dir()]:\n",
    "            clean_train_files.append(str(clean_train_file))\n",
    "\n",
    "    # setup pandas dataframe\n",
    "    df = pd.concat([pd.read_csv(x) for x in clean_train_files], sort=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('label')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 train examples\n",
      "49 validation examples\n",
      "61 test examples\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://storage.googleapis.com/applied-dl/heart.csv'\n",
    "dataframe = pd.read_csv(URL)\n",
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lat', 'lon', 'acc', 'bear', 'bearAcc', 'magnetometer_x',\n",
      "       'magnetometer_y', 'magnetometer_z', 'heading', '33_dbm', '25_dbm',\n",
      "       '181_dbm', '208_dbm', '200_dbm', '246_dbm', '188_dbm', '443_dbm',\n",
      "       'timestamp', 'intersection_points', 'label', '189_dbm', '459_dbm',\n",
      "       '195_dbm', '196_dbm', '476_dbm', '131_dbm', '484_dbm', '419_dbm'],\n",
      "      dtype='object')\n",
      "Index(['lat', 'lon', 'heading', '33_dbm', '25_dbm', '181_dbm', '208_dbm',\n",
      "       '200_dbm', '246_dbm', '188_dbm', '443_dbm', 'label', '189_dbm',\n",
      "       '459_dbm', '195_dbm', '196_dbm', '476_dbm', '131_dbm', '484_dbm',\n",
      "       '419_dbm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = get_dataframe_from_dir('1cid_nskip')\n",
    "d = {'SIDEWALK' : 0, 'ROAD' : 1}\n",
    "df = df.replace(d)\n",
    "df.fillna(0, inplace = True)\n",
    "\n",
    "print(df.columns)\n",
    "# include/exclude cid dbm fields\n",
    "if not args['dbm']:\n",
    "    dbm_columns = [column for column in df.columns if 'dbm' in column]\n",
    "    df.drop(columns=dbm_columns, inplace=True)\n",
    "\n",
    "# set of features to be used for training\n",
    "if 'features' in args:\n",
    "    f_col = [column for column in df.columns if column not in args['features'] and 'dbm' not in column and column != 'label']\n",
    "    df.drop(columns=f_col, inplace=True)\n",
    "print(df.columns)\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
