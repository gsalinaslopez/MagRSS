{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'dbm': True,\n",
    "        'batch_size': 128,\n",
    "        'features': ['heading', 'lat', 'lon']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_dir(train_data_dir):\n",
    "    \"\"\"\n",
    "    Crawls directory specified in @train_data_dir\n",
    "    Assumes the master train folder is located at `cwd`../train\n",
    "    \"\"\"\n",
    "    clean_train_files = []\n",
    "    main_train_dir_path = pathlib.Path(\n",
    "        pathlib.PurePath(pathlib.Path.cwd()).parent, pathlib.Path('train'))\n",
    "    \n",
    "    for train_dir in [x for x in main_train_dir_path.iterdir()\n",
    "                      if x.is_dir() and '.' not in x.name]:\n",
    "        clean_dir = train_dir / str(train_data_dir)\n",
    "        for clean_train_file in [x for x in clean_dir.iterdir() if not x.is_dir()]:\n",
    "            clean_train_files.append(str(clean_train_file))\n",
    "\n",
    "    # setup pandas dataframe\n",
    "    df = pd.concat([pd.read_csv(x) for x in clean_train_files], sort=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lat', 'lon', 'acc', 'bear', 'bearAcc', 'magnetometer_x',\n",
      "       'magnetometer_y', 'magnetometer_z', 'heading', '33_dbm', '25_dbm',\n",
      "       '181_dbm', '208_dbm', '200_dbm', '246_dbm', '188_dbm', '443_dbm',\n",
      "       'timestamp', 'intersection_points', 'label', '189_dbm', '459_dbm',\n",
      "       '195_dbm', '196_dbm', '476_dbm', '131_dbm', '484_dbm', '419_dbm'],\n",
      "      dtype='object')\n",
      "Index(['lat', 'lon', 'heading', '33_dbm', '25_dbm', '181_dbm', '208_dbm',\n",
      "       '200_dbm', '246_dbm', '188_dbm', '443_dbm', 'label', '189_dbm',\n",
      "       '459_dbm', '195_dbm', '196_dbm', '476_dbm', '131_dbm', '484_dbm',\n",
      "       '419_dbm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = get_dataframe_from_dir('1cid_nskip')\n",
    "d = {'SIDEWALK' : 0, 'ROAD' : 1}\n",
    "df = df.replace(d)\n",
    "df.fillna(0, inplace = True)\n",
    "\n",
    "print(df.columns)\n",
    "# include/exclude cid dbm fields\n",
    "if not args['dbm']:\n",
    "    dbm_columns = [column for column in df.columns if 'dbm' in column]\n",
    "    df.drop(columns=dbm_columns, inplace=True)\n",
    "\n",
    "# set of features to be used for training\n",
    "if 'features' in args:\n",
    "    f_col = [column for column in df.columns if column not in args['features'] and 'dbm' not in column and column != 'label']\n",
    "    df.drop(columns=f_col, inplace=True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            lat         lon     heading  33_dbm  25_dbm  181_dbm  208_dbm  \\\n",
      "3203  24.788743  120.994212 -168.481770       0       0      -75        0   \n",
      "3514  24.788199  120.994935   59.674255     -79       0        0        0   \n",
      "4648  24.788694  120.994200 -163.080180       0       0      -70        0   \n",
      "3320  24.789251  120.994184  160.660660       0       0      -81        0   \n",
      "514   24.788120  120.994646   14.574241       0       0      -77        0   \n",
      "...         ...         ...         ...     ...     ...      ...      ...   \n",
      "291   24.788777  120.994230 -159.378280       0       0      -74        0   \n",
      "651   24.788671  120.994959  -29.530804     -84       0        0        0   \n",
      "735   24.789465  120.994940   30.992434     -74       0        0        0   \n",
      "913   24.789235  120.995047   41.640860     -86       0        0        0   \n",
      "661   24.788883  120.995009   77.816080     -83       0        0        0   \n",
      "\n",
      "      200_dbm  246_dbm  188_dbm  443_dbm  label  189_dbm  459_dbm  195_dbm  \\\n",
      "3203      0.0      0.0      0.0      0.0      1      0.0      0.0      0.0   \n",
      "3514      0.0      0.0      0.0      0.0      1      0.0      0.0      0.0   \n",
      "4648      0.0      0.0      0.0      0.0      0      0.0      0.0      0.0   \n",
      "3320      0.0      0.0      0.0      0.0      0      0.0      0.0      0.0   \n",
      "514       0.0      0.0      0.0      0.0      1      0.0      0.0      0.0   \n",
      "...       ...      ...      ...      ...    ...      ...      ...      ...   \n",
      "291       0.0      0.0      0.0      0.0      1      0.0      0.0      0.0   \n",
      "651       0.0      0.0      0.0      0.0      1      0.0      0.0      0.0   \n",
      "735       0.0      0.0      0.0      0.0      1      0.0      0.0      0.0   \n",
      "913       0.0      0.0      0.0      0.0      0      0.0      0.0      0.0   \n",
      "661       0.0      0.0      0.0      0.0      1      0.0      0.0      0.0   \n",
      "\n",
      "      196_dbm  476_dbm  131_dbm  484_dbm  419_dbm  \n",
      "3203      0.0      0.0      0.0      0.0      0.0  \n",
      "3514      0.0      0.0      0.0      0.0      0.0  \n",
      "4648      0.0      0.0      0.0      0.0      0.0  \n",
      "3320      0.0      0.0      0.0      0.0      0.0  \n",
      "514       0.0      0.0      0.0      0.0      0.0  \n",
      "...       ...      ...      ...      ...      ...  \n",
      "291       0.0      0.0      0.0      0.0      0.0  \n",
      "651       0.0      0.0      0.0      0.0      0.0  \n",
      "735       0.0      0.0      0.0      0.0      0.0  \n",
      "913       0.0      0.0      0.0      0.0      0.0  \n",
      "661       0.0      0.0      0.0      0.0      0.0  \n",
      "\n",
      "[51167 rows x 20 columns]\n",
      "            lat         lon     heading  33_dbm  25_dbm  181_dbm  208_dbm  \\\n",
      "2335  24.789447  120.995041   -8.927646       0       0        0        0   \n",
      "76    24.789471  120.995014  -93.707080       0     -90        0        0   \n",
      "3307  24.789296  120.994139 -179.822050       0       0      -91        0   \n",
      "6361  24.788381  120.995081   70.551250     -79       0        0        0   \n",
      "1284  24.789192  120.995041 -131.669850       0     -80        0        0   \n",
      "...         ...         ...         ...     ...     ...      ...      ...   \n",
      "2413  24.788408  120.995092   81.575410     -78       0        0        0   \n",
      "464   24.788163  120.994403  133.969360       0       0      -70        0   \n",
      "2943  24.789579  120.994900 -144.337340       0       0        0        0   \n",
      "1085  24.788529  120.994255  163.129090       0       0      -70        0   \n",
      "255   24.788934  120.994105 -175.824600       0       0      -78        0   \n",
      "\n",
      "      200_dbm  246_dbm  188_dbm  443_dbm  label  189_dbm  459_dbm  195_dbm  \\\n",
      "2335      0.0      0.0    -69.0      0.0      0      0.0      0.0      0.0   \n",
      "76        0.0      0.0      0.0      0.0      0      0.0      0.0      0.0   \n",
      "3307      0.0      0.0      0.0      0.0      0      0.0      0.0      0.0   \n",
      "6361      0.0      0.0      0.0      0.0      0      0.0      0.0      0.0   \n",
      "1284      0.0      0.0      0.0      0.0      1      0.0      0.0      0.0   \n",
      "...       ...      ...      ...      ...    ...      ...      ...      ...   \n",
      "2413      0.0      0.0      0.0      0.0      0      0.0      0.0      0.0   \n",
      "464       0.0      0.0      0.0      0.0      1      0.0      0.0      0.0   \n",
      "2943      0.0      0.0    -62.0      0.0      0      0.0      0.0      0.0   \n",
      "1085      0.0      0.0      0.0      0.0      1      0.0      0.0      0.0   \n",
      "255       0.0      0.0      0.0      0.0      0      0.0      0.0      0.0   \n",
      "\n",
      "      196_dbm  476_dbm  131_dbm  484_dbm  419_dbm  \n",
      "2335      0.0      0.0      0.0      0.0      0.0  \n",
      "76        0.0      0.0      0.0      0.0      0.0  \n",
      "3307      0.0      0.0      0.0      0.0      0.0  \n",
      "6361      0.0      0.0      0.0      0.0      0.0  \n",
      "1284      0.0      0.0      0.0      0.0      0.0  \n",
      "...       ...      ...      ...      ...      ...  \n",
      "2413      0.0      0.0      0.0      0.0      0.0  \n",
      "464       0.0      0.0      0.0      0.0      0.0  \n",
      "2943      0.0      0.0      0.0      0.0      0.0  \n",
      "1085      0.0      0.0      0.0      0.0      0.0  \n",
      "255       0.0      0.0      0.0      0.0      0.0  \n",
      "\n",
      "[12792 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "\n",
    "print(train)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('target')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "df_to_dataset() got an unexpected keyword argument 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-71a900439308>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# setup data arrays from pandas dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_to_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mval_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_to_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_to_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: df_to_dataset() got an unexpected keyword argument 'df'"
     ]
    }
   ],
   "source": [
    "# setup data arrays from pandas dataframe\n",
    "batch_size = args['batch_size']\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "steps_per_epoch = len(train.index) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
