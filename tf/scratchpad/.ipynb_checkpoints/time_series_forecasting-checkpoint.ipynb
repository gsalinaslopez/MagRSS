{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "    fname='jena_climate_2009_2016.csv.zip',\n",
    "    extract=True)\n",
    "csv_path, _ = os.path.splitext(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_data(dataset, start_index, end_index, history_size, target_size):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  print(range(start_index, end_index))\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i)\n",
    "    # Reshape data from (history_size,) to (history_size, 1)\n",
    "    data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "    labels.append(dataset[i+target_size])\n",
    "  return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = 300000\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_data = df['T (degC)']\n",
    "uni_data.index = df['Date Time']\n",
    "uni_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_data.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uni_data)\n",
    "uni_data = uni_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uni_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_train_mean = uni_data[:TRAIN_SPLIT].mean()\n",
    "uni_train_std = uni_data[:TRAIN_SPLIT].std()\n",
    "\n",
    "uni_data = (uni_data-uni_train_mean)/uni_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(uni_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_past_history = 20\n",
    "univariate_future_target = 0\n",
    "\n",
    "x_train_uni, y_train_uni = univariate_data(uni_data, 0, TRAIN_SPLIT,\n",
    "                                           univariate_past_history,\n",
    "                                           univariate_future_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_uni, y_val_uni = univariate_data(uni_data, TRAIN_SPLIT, None,\n",
    "                                       univariate_past_history,\n",
    "                                       univariate_future_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Single window of past history')\n",
    "print (x_train_uni[0])\n",
    "print ('\\n Target temperature to predict')\n",
    "print (y_train_uni[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_steps(length):\n",
    "  time_steps = []\n",
    "  for i in range(-length, 0, 1):\n",
    "    time_steps.append(i)\n",
    "  return time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(plot_data, delta, title):\n",
    "  labels = ['History', 'True Future', 'Model Prediction']\n",
    "  marker = ['.-', 'rx', 'go']\n",
    "  time_steps = create_time_steps(plot_data[0].shape[0])\n",
    "  if delta:\n",
    "    future = delta\n",
    "  else:\n",
    "    future = 0\n",
    "\n",
    "  plt.title(title)\n",
    "  for i, x in enumerate(plot_data):\n",
    "    if i:\n",
    "      plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
    "               label=labels[i])\n",
    "    else:\n",
    "      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "  plt.legend()\n",
    "  plt.xlim([time_steps[0], (future+5)*2])\n",
    "  plt.xlabel('Time-Step')\n",
    "  return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = [x_train_uni[0], y_train_uni[0]]\n",
    "for i, x in enumerate(o):\n",
    "    print(i, x)\n",
    "print(enumerate(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plot([x_train_uni[0], y_train_uni[0]], 0, 'Sample Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(history):\n",
    "  return np.mean(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plot([x_train_uni[0], y_train_uni[0], baseline(x_train_uni[0])], 0,\n",
    "           'Baseline Prediction Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\n",
    "train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\n",
    "val_univariate = val_univariate.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(8, input_shape=x_train_uni.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "metrics=['accuracy', 'binary_crossentropy']\n",
    "\n",
    "simple_lstm_model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_uni.shape)\n",
    "print(x_train_uni.shape[-2:])\n",
    "print(x_train_uni.shape[0] // 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_univariate.take(1):\n",
    "    print(x, y)\n",
    "    print(simple_lstm_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_INTERVAL = 200\n",
    "EPOCHS = 10\n",
    "EVALUATION_INTERVAL = x_train_uni.shape[0] // BATCH_SIZE\n",
    "EVALUATIN_INTERVAL = 2000\n",
    "simple_lstm_model.fit(train_univariate, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate, validation_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_univariate.take(3):\n",
    "  plot = show_plot([x[0].numpy(), y[0].numpy(),\n",
    "                    simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')\n",
    "  plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_considered = ['p (mbar)', 'T (degC)', 'rho (g/m**3)']\n",
    "features = df[features_considered]\n",
    "features.index = df['Date Time']\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = features.values\n",
    "data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)\n",
    "data_std = dataset[:TRAIN_SPLIT].std(axis=0)\n",
    "dataset = (dataset-data_mean)/data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "    data.append(dataset[indices])\n",
    "\n",
    "    if single_step:\n",
    "      labels.append(target[i+target_size])\n",
    "    else:\n",
    "      labels.append(target[i:i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_history = 720\n",
    "future_target = 72\n",
    "STEP = 6\n",
    "\n",
    "x_train_single, y_train_single = multivariate_data(dataset, dataset[:, 1], 0,\n",
    "                                                   TRAIN_SPLIT, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=True)\n",
    "x_val_single, y_val_single = multivariate_data(dataset, dataset[:, 1],\n",
    "                                               TRAIN_SPLIT, None, past_history,\n",
    "                                               future_target, STEP,\n",
    "                                               single_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "x_train_single_ts = TimeseriesGenerator(data=dataset, targets=dataset[:, 1], \n",
    "                                        start_index=0, end_index=TRAIN_SPLIT,\n",
    "                                        length=past_history, sampling_rate=STEP,\n",
    "                                        stride=future_target)\n",
    "x, y = x_train_single_ts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_single[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Single window of past history : {}'.format(x_train_single[0].shape))\n",
    "print ('Single window of past history : {}'.format(x[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[i] for i in range(14400)])\n",
    "targets = np.array([[i] for i in range(14400)])\n",
    "\n",
    "data_single_x, data_single_y = multivariate_data(data, targets, 0, None, past_history,\n",
    "                                                 future_target, STEP, single_step=False)\n",
    "data_ts = TimeseriesGenerator(data=data, targets=targets,start_index = 0, end_index = len(data) - 1, \n",
    "                              length=past_history, sampling_rate=STEP, batch_size=len(data))#, stride=future_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[    0]\n",
      "  [    6]\n",
      "  [   12]\n",
      "  ...\n",
      "  [  702]\n",
      "  [  708]\n",
      "  [  714]]\n",
      "\n",
      " [[    1]\n",
      "  [    7]\n",
      "  [   13]\n",
      "  ...\n",
      "  [  703]\n",
      "  [  709]\n",
      "  [  715]]\n",
      "\n",
      " [[    2]\n",
      "  [    8]\n",
      "  [   14]\n",
      "  ...\n",
      "  [  704]\n",
      "  [  710]\n",
      "  [  716]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[13605]\n",
      "  [13611]\n",
      "  [13617]\n",
      "  ...\n",
      "  [14307]\n",
      "  [14313]\n",
      "  [14319]]\n",
      "\n",
      " [[13606]\n",
      "  [13612]\n",
      "  [13618]\n",
      "  ...\n",
      "  [14308]\n",
      "  [14314]\n",
      "  [14320]]\n",
      "\n",
      " [[13607]\n",
      "  [13613]\n",
      "  [13619]\n",
      "  ...\n",
      "  [14309]\n",
      "  [14315]\n",
      "  [14321]]] [[[  720]\n",
      "  [  721]\n",
      "  [  722]\n",
      "  ...\n",
      "  [  789]\n",
      "  [  790]\n",
      "  [  791]]\n",
      "\n",
      " [[  721]\n",
      "  [  722]\n",
      "  [  723]\n",
      "  ...\n",
      "  [  790]\n",
      "  [  791]\n",
      "  [  792]]\n",
      "\n",
      " [[  722]\n",
      "  [  723]\n",
      "  [  724]\n",
      "  ...\n",
      "  [  791]\n",
      "  [  792]\n",
      "  [  793]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[14325]\n",
      "  [14326]\n",
      "  [14327]\n",
      "  ...\n",
      "  [14394]\n",
      "  [14395]\n",
      "  [14396]]\n",
      "\n",
      " [[14326]\n",
      "  [14327]\n",
      "  [14328]\n",
      "  ...\n",
      "  [14395]\n",
      "  [14396]\n",
      "  [14397]]\n",
      "\n",
      " [[14327]\n",
      "  [14328]\n",
      "  [14329]\n",
      "  ...\n",
      "  [14396]\n",
      "  [14397]\n",
      "  [14398]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(data_single_x, data_single_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "======================================================================\n",
      "[[[    0]\n",
      "  [    6]\n",
      "  [   12]\n",
      "  ...\n",
      "  [  702]\n",
      "  [  708]\n",
      "  [  714]]\n",
      "\n",
      " [[    1]\n",
      "  [    7]\n",
      "  [   13]\n",
      "  ...\n",
      "  [  703]\n",
      "  [  709]\n",
      "  [  715]]\n",
      "\n",
      " [[    2]\n",
      "  [    8]\n",
      "  [   14]\n",
      "  ...\n",
      "  [  704]\n",
      "  [  710]\n",
      "  [  716]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[13677]\n",
      "  [13683]\n",
      "  [13689]\n",
      "  ...\n",
      "  [14379]\n",
      "  [14385]\n",
      "  [14391]]\n",
      "\n",
      " [[13678]\n",
      "  [13684]\n",
      "  [13690]\n",
      "  ...\n",
      "  [14380]\n",
      "  [14386]\n",
      "  [14392]]\n",
      "\n",
      " [[13679]\n",
      "  [13685]\n",
      "  [13691]\n",
      "  ...\n",
      "  [14381]\n",
      "  [14387]\n",
      "  [14393]]] [[  720]\n",
      " [  721]\n",
      " [  722]\n",
      " ...\n",
      " [14397]\n",
      " [14398]\n",
      " [14399]]\n"
     ]
    }
   ],
   "source": [
    "#data_ts_x, data_ts_y = data_ts\n",
    "print(len(data_ts))\n",
    "for x, y in data_ts:\n",
    "    print('======================================================================')\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_single_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ts_x, data_ts_y = data_ts[0]\n",
    "data_ts_y += future_target\n",
    "print(data_ts_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
